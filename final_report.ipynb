{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 2 Final Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before conducting data transformations and analysis, a general understanding of how we got the data to this point is required. In our command line we spun up the data pipeline described in the docker-compose.yml file. It involved creating a zookeeper, kafka, cloudera, spark, and mids base container. After spinning that up using docker-compose, we checked our HDFS instance through cloudera in the /tmp/ folder. This check confirmed that we would have a place in HDFS to land our data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After also confirming that our Kafka and Zookeeper containers were up and running, the next step was to create our Kafka topic. A Kafka topic is basically a category you declare to organize data. This data is sent to and received from the topic in the form of messages (or packets of data). For this project we named the topic 'assessments' because the JSON data that we're reading in is assessments data. After topic creation we can confirm that the topic exists before we begin exploring our JSON file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help determine how we should read in the data, we used various jq commands to output various parts of the JSON file. From these commands we determined many useful facts about the data:\n",
    "1. The JSON file has 3280 elements, numbered 0-3279, that each represent an assessment attempt. We will want each of these elements to be passed through the Kafka topic as a message. In total our topic will produce 3280 messages.\n",
    "2. Each element has nested features specific to the individual attempt being described. The fields all seem uniform across elements apart from the \"questions\" array. We cannot assume that each assessment has the same number of questions, so we will have to figure out how to dynamically read that data in for each attempt. \n",
    "3. Inside the \"questions\" array, there's a nested \"options\" array. It's not clear what this data is really representing, so I'm assuming that it does not need to be included in our transformed data.\n",
    "4. I also noticed from doing a pretty print of the whole JSON file that some of the values in the exam_name field are padded with whitespace. This means we'll either have to ensure they're trimmed when transforming OR use the base_exam_id field as a unique id for each assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the exploratory data analysis in our command line, we will publish these messages (JSON elements) to our Kafka topic. We can then consume them from the topic and run the wc command to ensure that all 3280 messages were passed correctly. However, we don't just want them to be consumed by Kafka, we want to land the data into Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "raw_assess = spark \\\n",
    "  .read \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"kafka:29092\") \\\n",
    "  .option(\"subscribe\",\"assessments\") \\\n",
    "  .option(\"startingOffsets\", \"earliest\") \\\n",
    "  .option(\"endingOffsets\", \"latest\") \\\n",
    "  .load() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: binary, value: binary, topic: string, partition: int, offset: bigint, timestamp: timestamp, timestampType: int]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_assess.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When passing data from Kafka into Spark, it automatically saves it as an RDD (Resilient Distributed Dataset) with key value pairs. The values are currently in hexadecimal format, so the data is not very meaningful without some base treansformations performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+-----------+---------+------+--------------------+-------------+\n",
      "| key|               value|      topic|partition|offset|           timestamp|timestampType|\n",
      "+----+--------------------+-----------+---------+------+--------------------+-------------+\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|     0|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|     1|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|     2|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|     3|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|     4|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|     5|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|     6|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|     7|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|     8|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|     9|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|    10|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|    11|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|    12|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|    13|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|    14|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|    15|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|    16|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|    17|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|    18|1969-12-31 23:59:...|            0|\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|    19|1969-12-31 23:59:...|            0|\n",
      "+----+--------------------+-----------+---------+------+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_assess.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing to note is the length of the RDD coming into Spark from Kafka. This length corresponds to the number of messages that we produced in our Kafka topic and then consumed, which should be 3280 messages. In the context of the data, this represents 3280 assessments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3280"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_assess.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going back to the raw_assess RDD, all of the columns apart from the 'value' column, everything from key to topic-timestampType, are not required for our transformations or analysis. So, our first step will be to remove these unnecessary columns and cast the value column as a string so that we can start to see our data entries in a readable format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "assessments = raw_assess.select(raw_assess.value.cast('string'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assessments.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this string casting, we can start to see the data inside each of the elements in the JSON file we read from. However, before we continue our transformations we need to write this raw data as a parquet file to write it to HDFS (Hadoop Distributed File System). Once we have this version of the data saved, we can read it back in and continue applying transformations to it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "assessments.write.parquet(\"/tmp/assessments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "read_assess = spark.read.parquet('/tmp/assessments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_json, col\n",
    "import json\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import explode, split\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, TimestampType, ArrayType\n",
    "import warnings\n",
    "from pyspark.sql.functions import size\n",
    "from pyspark.sql.functions import regexp_replace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using the JSON library, we can convert our RDD into DataFrame format for easier manipulation. After that we can print the schema to see what this function picked up about the format of each of the assessment elements from our nested JSON file. Remember that this is creating one row for each assessment attempt (3280 total - as confirmed by the length of the initial RDD) and each column represents an element of the base hierarchy within an assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/spark-2.2.0-bin-hadoop2.6/python/pyspark/sql/session.py:351: UserWarning: Using RDD of dict to inferSchema is deprecated. Use pyspark.sql.Row instead\n",
      "  warnings.warn(\"Using RDD of dict to inferSchema is deprecated. \"\n"
     ]
    }
   ],
   "source": [
    "extracted_assessments = read_assess.rdd.map(lambda x: json.loads(x.value)).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- base_exam_id: string (nullable = true)\n",
      " |-- certification: string (nullable = true)\n",
      " |-- exam_name: string (nullable = true)\n",
      " |-- keen_created_at: string (nullable = true)\n",
      " |-- keen_id: string (nullable = true)\n",
      " |-- keen_timestamp: string (nullable = true)\n",
      " |-- max_attempts: string (nullable = true)\n",
      " |-- sequences: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: array (valueContainsNull = true)\n",
      " |    |    |-- element: map (containsNull = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: boolean (valueContainsNull = true)\n",
      " |-- started_at: string (nullable = true)\n",
      " |-- user_exam_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extracted_assessments.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the json.loads function correctly identified all of the objects at the top of the hierarchy. However, it cannot correctly unnest the objects within 'sequences'. From pretty printing the original JSON file using jq commands, we know that sequences contains an array of important values. It has a nested array representing the questions in the assessment and another array of values 'counts', which provides data on things like number of submitted attempts, incomplete attempts, etc. In order to get all of this data that the inferred schema did not pick up, we will have to forcibly define the schema shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "final_schema = StructType([StructField('exam_name', StringType(), True),\n",
    "                     StructField('base_exam_id', StringType(), True),\n",
    "                     StructField('max_attempts', StringType(), True),\n",
    "                     StructField('sequences', StructType([\n",
    "                         StructField('questions', ArrayType(StringType()), True),\n",
    "                         StructField('counts', StructType([\n",
    "                             StructField('incomplete', StringType(), True),\n",
    "                             StructField('submitted', StringType(), True),\n",
    "                             StructField('incorrect', StringType(), True),\n",
    "                             StructField('all_correct', StringType(), True),\n",
    "                             StructField('correct', StringType(), True),\n",
    "                             StructField('total', StringType(), True),\n",
    "                             StructField('unanswered', StringType(), True),\n",
    "                         ]))]))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the final schema we chose to transform the assessment data into. To handle the multiple questions inside the \"sequences\" element, we declared \"questions\" as an ArrayType and then we can get the size of it to return the number of questions in that particular element. For the purposes of new customers querying the data, we believe that's the only relevant portion of the questions objects. We also included all the fields within the \"counts\" array because they provide interesting insights regarding the attempt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "final_extracted_assessments = read_assess.rdd.map(lambda x: json.loads(x.value)).toDF(schema=final_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- exam_name: string (nullable = true)\n",
      " |-- base_exam_id: string (nullable = true)\n",
      " |-- max_attempts: string (nullable = true)\n",
      " |-- sequences: struct (nullable = true)\n",
      " |    |-- questions: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- counts: struct (nullable = true)\n",
      " |    |    |-- incomplete: string (nullable = true)\n",
      " |    |    |-- submitted: string (nullable = true)\n",
      " |    |    |-- incorrect: string (nullable = true)\n",
      " |    |    |-- all_correct: string (nullable = true)\n",
      " |    |    |-- correct: string (nullable = true)\n",
      " |    |    |-- total: string (nullable = true)\n",
      " |    |    |-- unanswered: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_extracted_assessments.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After coverting the original RDD into a dataframe (and forcing the finalized schema), we can see that the nested fields\n",
    "now appear correctly when we run .printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "final_extracted_assessments.registerTempTable('final_ex_assessments_tb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "transf_assessments = spark.sql(\"select trim(exam_name) as exam_name, base_exam_id, max_attempts, sequences.questions, \\\n",
    "                                sequences.counts.incomplete, sequences.counts.submitted, sequences.counts.incorrect, \\\n",
    "                                sequences.counts.all_correct, sequences.counts.correct, sequences.counts.total, \\\n",
    "                                sequences.counts.unanswered from final_ex_assessments_tb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To utilize Spark SQL features we have to first register our dataframe as a temporary table. From there, we can access the nested fields of the dataframe using the dot operator as shown above. This will essentially flatted the schema as shown when we print the schema out again below. We also generated the num_questions column as described previously by taking the size of the questions column. This resulting column represents the number of questions for a given exam and taking the *size* works because we declared that column to be an ArrayType."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "transf_assessments = transf_assessments.withColumn(\"num_questions\", size(col(\"questions\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- exam_name: string (nullable = true)\n",
      " |-- base_exam_id: string (nullable = true)\n",
      " |-- max_attempts: string (nullable = true)\n",
      " |-- questions: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- incomplete: string (nullable = true)\n",
      " |-- submitted: string (nullable = true)\n",
      " |-- incorrect: string (nullable = true)\n",
      " |-- all_correct: string (nullable = true)\n",
      " |-- correct: string (nullable = true)\n",
      " |-- total: string (nullable = true)\n",
      " |-- unanswered: string (nullable = true)\n",
      " |-- num_questions: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transf_assessments.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "transf_assessments.registerTempTable('transf_assessments_tb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "trans_assessment_out = spark.sql(\"select exam_name, base_exam_id, max_attempts, \\\n",
    "                                num_questions, incomplete, submitted, incorrect, \\\n",
    "                                all_correct, correct as num_correct, total, unanswered \\\n",
    "                                from transf_assessments_tb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the schema has been flattened, we no longer have to use the dot operator to reference fields. See an sample outout of the final transformed table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+-------------+----------+---------+---------+-----------+-----------+-----+----------+\n",
      "|           exam_name|        base_exam_id|max_attempts|num_questions|incomplete|submitted|incorrect|all_correct|num_correct|total|unanswered|\n",
      "+--------------------+--------------------+------------+-------------+----------+---------+---------+-----------+-----------+-----+----------+\n",
      "|Normal Forms and ...|37f0a30a-7464-11e...|         1.0|            4|         1|        4|        1|      false|          2|    4|         0|\n",
      "|Normal Forms and ...|37f0a30a-7464-11e...|         1.0|            4|         2|        4|        1|      false|          1|    4|         0|\n",
      "|The Principles of...|4beeac16-bb83-4d5...|         1.0|            4|         0|        4|        1|      false|          3|    4|         0|\n",
      "|The Principles of...|4beeac16-bb83-4d5...|         1.0|            4|         2|        4|        0|      false|          2|    4|         0|\n",
      "|Introduction to B...|6442707e-7488-11e...|         1.0|            4|         0|        4|        1|      false|          3|    4|         0|\n",
      "+--------------------+--------------------+------------+-------------+----------+---------+---------+-----------+-----------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trans_assessment_out.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After transforming the data using Spark, we will again write this table to a parquet file, which will save it onto HDFS. Once we read it back in we can query it to emulate how a new customer's data science team would do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "trans_assessment_out.write.parquet(\"/tmp/queryable_assessments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 Business Questions\n",
    "1. How many assessments are on this platform?\n",
    "2. What are the top 5 most frequently taken assessments?\n",
    "3. Average number of questions? \n",
    "4. What the average score (num correct / total) for each assessment? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we are reading in the parquet file, registering a temporary table, and printing the schema to check that it was read in from HDFS correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "read_trans_assess = spark.read.parquet('/tmp/queryable_assessments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "read_trans_assess.registerTempTable('questions_tb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- exam_name: string (nullable = true)\n",
      " |-- base_exam_id: string (nullable = true)\n",
      " |-- max_attempts: string (nullable = true)\n",
      " |-- num_questions: integer (nullable = true)\n",
      " |-- incomplete: string (nullable = true)\n",
      " |-- submitted: string (nullable = true)\n",
      " |-- incorrect: string (nullable = true)\n",
      " |-- all_correct: string (nullable = true)\n",
      " |-- num_correct: string (nullable = true)\n",
      " |-- total: string (nullable = true)\n",
      " |-- unanswered: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_trans_assess.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Business Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the transformed data successfully saved in HDFS, we ran some sample business questions to give new customers a taste of the kind of business questions they can get answers to from the assessments data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How many assessments are on this platform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-------------------------+\n",
      "|count(DISTINCT base_exam_id)|count(DISTINCT exam_name)|\n",
      "+----------------------------+-------------------------+\n",
      "|                         107|                      103|\n",
      "+----------------------------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q1 = spark.sql(\"select count (distinct base_exam_id), count(distinct exam_name) from questions_tb\")\n",
    "q1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This question brought to light an issue with the data. As mentioned earlier in the report, some of the values in the \"exam_name\" column were padded with white space, so there could be multiple exam_name values for the same base_exam_id value. This query confirmed that suspicion. We had tried to trim the exam_name column to remove the white space padding, but that did not work clearly. This is still an open issue with the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What are the top 5 most attempted assessments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+------------------------------------+------------+\n",
      "|exam_name                      |base_exam_id                        |num_attempts|\n",
      "+-------------------------------+------------------------------------+------------+\n",
      "|Learning Git                   |8b4488de-43a5-4ffa-bf82-af1e19ee1b64|394         |\n",
      "|Introduction to Java 8         |41858ac3-1394-451b-bf7c-c10f52034a9a|158         |\n",
      "|Intermediate Python Programming|1a233da8-e6e5-48a6-8c3c-806e312cce12|158         |\n",
      "|Learning to Program with R     |b114e4a4-a192-4dff-a5cd-8e7782bb1623|128         |\n",
      "|Introduction to Python         |7e2e0b53-a7ba-458d-8bc6-356f8dea8815|122         |\n",
      "+-------------------------------+------------------------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q2 = spark.sql(\"select exam_name, base_exam_id, count(*) as num_attempts from questions_tb \\\n",
    "            group by exam_name, base_exam_id \\\n",
    "            order by num_attempts DESC \\\n",
    "            limit 5\")\n",
    "q2.show(5,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. What are the average number of questions for an assessment on our platform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|avg_num_questions|\n",
      "+-----------------+\n",
      "|4.317757009345795|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q3 = spark.sql(\"with input as (select avg(num_questions) as avg_num_questions \\\n",
    "               from questions_tb \\\n",
    "                group by base_exam_id) \\\n",
    "                select avg(avg_num_questions) as avg_num_questions from input\")\n",
    "q3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. What's the average score for each exam?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score for an exam will be calculated using sequences.counts.correct / sequences.counts.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------+\n",
      "|     trim(exam_name)|        base_exam_id|avg_score|\n",
      "+--------------------+--------------------+---------+\n",
      "|Mastering Python ...|dd9e3175-45a4-491...|     0.74|\n",
      "|Learning Linux Se...|76f39b28-76be-11e...|     0.62|\n",
      "|Introduction to A...|f9de34a3-748d-11e...|     0.83|\n",
      "|Learning C# Desig...|a8dedd1d-0f67-4f4...|     0.72|\n",
      "|Learning Data Mod...|479f39cc-70a9-11e...|      0.5|\n",
      "|An Introduction t...|9ff51f14-7525-11e...|     0.59|\n",
      "|Git Fundamentals ...|e1f07fac-5566-4fd...|     0.75|\n",
      "|Hadoop Fundamenta...|b4da3808-7474-11e...|     0.67|\n",
      "|Amazon Web Servic...|f0633ed7-748d-11e...|      0.5|\n",
      "|Using R for Big D...|526908f1-9c67-4ab...|     0.56|\n",
      "|Introduction to A...|0161dadc-748e-11e...|     0.55|\n",
      "|The Closed World ...|f224b886-745e-11e...|      1.0|\n",
      "|Data Visualizatio...|5a1a0072-47c5-478...|     0.49|\n",
      "|Starting a Grails...|b0011798-80dd-4cb...|     0.75|\n",
      "|Modeling for Soft...|f83fae20-8d97-40d...|     0.65|\n",
      "|        Learning SQL|a3cf5a0f-6bd8-11e...|     0.74|\n",
      "|Operating Red Hat...|3aa9edb7-6031-41f...|     0.55|\n",
      "|          Great Bash|0fed9e6e-6438-464...|     0.59|\n",
      "|Mastering Advance...|4b546345-b897-418...|     0.36|\n",
      "|Design Patterns i...|500c5332-2ab4-4f6...|     0.47|\n",
      "+--------------------+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q4 = spark.sql(\"select trim(exam_name), base_exam_id, round(avg(num_correct / total),2) as avg_score \\\n",
    "                from questions_tb \\\n",
    "                group by exam_name, base_exam_id\")\n",
    "q4.show(20)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m78",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m78"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
